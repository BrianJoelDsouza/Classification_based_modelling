{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br><h1>A1 - Regression based Analysis</h1>\n",
    "<h3> Machine Learning </h3><br><br>\n",
    "Submitted by - Brian Dsouza<br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "<h2>Exploratory Data Analysis</h2>\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas                  as pd    \n",
    "import matplotlib.pyplot       as plt\n",
    "import seaborn                 as sns\n",
    "import statsmodels.formula.api as smf \n",
    "from sklearn.model_selection   import train_test_split \n",
    "from sklearn.neighbors         import KNeighborsRegressor \n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from sklearn.linear_model      import LogisticRegression         \n",
    "from sklearn.metrics           import confusion_matrix           \n",
    "from sklearn.metrics           import roc_auc_score            \n",
    "from sklearn.neighbors         import KNeighborsClassifier       \n",
    "from sklearn.neighbors         import KNeighborsRegressor        \n",
    "from sklearn.preprocessing     import StandardScaler             \n",
    "from sklearn.tree              import DecisionTreeClassifier     \n",
    "from sklearn.tree              import export_graphviz           \n",
    "from sklearn.externals.six     import StringIO                   \n",
    "from IPython.display           import Image                     \n",
    "import pydotplus                                                 \n",
    "from sklearn.model_selection   import GridSearchCV               \n",
    "from sklearn.metrics           import make_scorer                \n",
    "from sklearn.ensemble          import RandomForestClassifier     \n",
    "from sklearn.ensemble          import GradientBoostingClassifier \n",
    "\n",
    "#Saving the file path in an object named file\n",
    "file = \"Apprentice_Chef_Dataset.xlsx\"\n",
    "\n",
    "#Reading the file into Python for analysis\n",
    "original_df = pd.read_excel(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<h6>User defined functions that are used throughout in this script</h6>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#Creating a function to flag missing values, mv_flagger(df)\n",
    "##############################################################\n",
    "def mv_flagger(df):\n",
    "    \"\"\"\n",
    "Flags all columns that have missing values with 'm_(COLUMN NAME)'.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "df : DataFrame to flag missing values\n",
    "\n",
    "\n",
    "RETURNS\n",
    "-------\n",
    "DataFrame with missing value flags.\"\"\"\n",
    "\n",
    "\n",
    "    for col in df:\n",
    "\n",
    "        if df[col].isnull().astype(int).sum() > 0:\n",
    "            df['m_'+col] = df[col].isnull().astype(int)\n",
    "            \n",
    "    return df\n",
    "\n",
    "#########################\n",
    "# text_split_feature\n",
    "#########################\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))\n",
    "        \n",
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=802,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 802\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled           = scaler.transform(X_data)\n",
    "        X_scaled_df        = pd.DataFrame(X_scaled)\n",
    "        X_data             = X_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()\n",
    "    \n",
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width)\n",
    "    \n",
    "    return img\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the entire file\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the column names\n",
    "list(original_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the info on each variable\n",
    "original_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the descriptive statistics of each column, round to 2 decimals\n",
    "original_df.iloc[:, :].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see if any columns have missing values and summing them up to find the total of missing values per column\n",
    "original_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the variable values of quantiles 0.20, 0.40, 0.60, 0.80, 1.00\n",
    "original_df.loc[:, :].quantile([0.20,\n",
    "                                0.40,\n",
    "                                0.60,\n",
    "                                0.80,\n",
    "                                1.00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.loc[:, 'AVG_TIME_PER_SITE_VISIT'].quantile([0.90,\n",
    "#                                                        0.95,\n",
    "#                                                        0.99,\n",
    "#                                                        1.00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df[original_df['AVG_TIME_PER_SITE_VISIT'] > 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df[original_df['AVG_TIME_PER_SITE_VISIT'] > 1500].loc[:, 'AVG_TIME_PER_SITE_VISIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.loc[:, 'TOTAL_MEALS_ORDERED'].quantile([0.90,\n",
    "#                                                    0.95,\n",
    "#                                                    0.99,\n",
    "#                                                    1.00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df[original_df['TOTAL_MEALS_ORDERED'] > 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.loc[:, 'AVG_PREP_VID_TIME'].quantile([0.90,\n",
    "#                                                  0.95,\n",
    "#                                                  0.99,\n",
    "#                                                  1.00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df[original_df['AVG_PREP_VID_TIME'] > 550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.loc[:, 'TOTAL_PHOTOS_VIEWED'].quantile([0.90,\n",
    "#                                                    0.95,\n",
    "#                                                    0.99,\n",
    "#                                                    1.00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df[original_df['TOTAL_PHOTOS_VIEWED'] > 1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Making assumptions about each variable's data type, if it is Continuous, Discrete, Binary, Count, Categorical, so that\n",
    "a suitable strategy can be applied to engineer the features.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Continuous:\n",
    "REVENUE\n",
    "PRODUCT_CATEGORIES_VIEWED (also in another place)\n",
    "AVG_TIME_PER_SITE_VISIT\n",
    "CANCELLATIONS_BEFORE_NOON (also in another place)\n",
    "CANCELLATIONS_AFTER_NOON  (also in another place)\n",
    "MOBILE_LOGINS             (also in another place)\n",
    "PC_LOGINS                 (also in another place)\n",
    "WEEKLY_PLAN               (also in another place)\n",
    "EARLY_DELIVERIES          (also in another place)\n",
    "LATE_DELIVERIES           (also in another place)\n",
    "AVG_PREP_VID_TIME\n",
    "AVG_CLICKS_PER_VISIT\n",
    "TOTAL_PHOTOS_VIEWED\n",
    "\n",
    "Binary:\n",
    "CROSS_SELL_SUCCESS\n",
    "MOBILE_NUMBER\n",
    "TASTES_AND_PREFERENCES\n",
    "PACKAGE_LOCKER\n",
    "REFRIGERATED_LOCKER\n",
    "\n",
    "\n",
    "Count:\n",
    "TOTAL_MEALS_ORDERED\n",
    "UNIQUE_MEALS_PURCH\n",
    "CONTACTS_W_CUSTOMER_SERVICE\n",
    "PRODUCT_CATEGORIES_VIEWED (also in another place)\n",
    "CANCELLATIONS_BEFORE_NOON (also in another place)\n",
    "CANCELLATIONS_AFTER_NOON  (also in another place)\n",
    "MOBILE_LOGINS             (also in another place)\n",
    "PC_LOGINS                 (also in another place)\n",
    "WEEKLY_PLAN               (also in another place)\n",
    "EARLY_DELIVERIES          (also in another place)\n",
    "LATE_DELIVERIES           (also in another place)\n",
    "MASTER_CLASSES_ATTENDED\n",
    "\n",
    "Discrete:\n",
    "FOLLOWED_RECOMMENDATIONS_PCT\n",
    "LARGEST_ORDER_SIZE\n",
    "MEDIAN_MEAL_RATING\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<h2>Feature treatment and Engineering</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting EMAIL column to find different domains\n",
    "\n",
    "#Creating a temporary placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "#Looping over each email address\n",
    "for index, col in original_df.iterrows(): #The iterrows() function is used to iterate over DataFrame rows as (index, Series) pairs. Iterates over the DataFrame columns, returning a tuple with the column name and the content as a Series.\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = original_df.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating with apprentice_chef \n",
    "\n",
    "#Renaming the email_df columns \n",
    "email_df.columns = ['0' , 'EMAIL_DOMAIN']\n",
    "\n",
    "\n",
    "#Concatenating email_domain with apprentice_chef\n",
    "original_df = pd.concat([original_df, email_df['EMAIL_DOMAIN']],\n",
    "                            axis = 1)\n",
    "\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing value counts of email_domain\n",
    "original_df.loc[: ,'EMAIL_DOMAIN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column for email domain groups - personal, professional, junk\n",
    "personal_email_domains      = ['gmail.com', \n",
    "                               'protonmail.com', \n",
    "                               'yahoo.com']\n",
    "professional_email_domains  = ['amex.com', \n",
    "                               'merck.com', \n",
    "                               'cocacola.com', \n",
    "                               'jnj.com', \n",
    "                               'mcdonalds.com', \n",
    "                               'nike.com', \n",
    "                               'apple.com', \n",
    "                               'ge.org', \n",
    "                               'dupont.com', \n",
    "                               'ibm.com', \n",
    "                               'chevron.com', \n",
    "                               'microsoft.com', \n",
    "                               'travelers.com', \n",
    "                               'exxon.com', \n",
    "                               'unitedhealth.com', \n",
    "                               'boeing.com', \n",
    "                               'verizon.com', \n",
    "                               'mmm.com', \n",
    "                               'caterpillar.com', \n",
    "                               'pg.com', \n",
    "                               'disney.com', \n",
    "                               'walmart.com', \n",
    "                               'pfizer.com', \n",
    "                               'visa.com', \n",
    "                               'jpmorgan.com', \n",
    "                               'cisco.com', \n",
    "                               'goldmansacs.com', \n",
    "                               'unitedtech.com', \n",
    "                               'homedepot.com', \n",
    "                               'intel.com']\n",
    "junk_email_domains          = ['msn.com', \n",
    "                               'aol.com', \n",
    "                               'passport.com', \n",
    "                               'hotmail.com', \n",
    "                               'live.com', \n",
    "                               'me.com']\n",
    "\n",
    "#Placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in original_df['EMAIL_DOMAIN']:\n",
    "    \n",
    "    if domain in personal_email_domains:\n",
    "        placeholder_lst.append('personal')\n",
    "        \n",
    "\n",
    "    elif domain in professional_email_domains:\n",
    "        placeholder_lst.append('professional')\n",
    "\n",
    "    elif domain in junk_email_domains:\n",
    "        placeholder_lst.append('junk')\n",
    "\n",
    "    else:\n",
    "            print('Unknown')\n",
    "\n",
    "\n",
    "#Creating a new column called DOMAIN_TYPE\n",
    "original_df['DOMAIN_TYPE'] = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.groupby('DOMAIN_TYPE').agg({'CROSS_SELL_SUCCESS': ['count','sum', 'mean']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> INSIGHT: 1 </h5> <br><br>\n",
    "* The success rate (=1) of promoting Halfway there is on average very high (~80%) among customers that register using their professional email id.<br>\n",
    "* Customers using personal email id subscribe to the promotion more, 602 in total, compared to the other 2 email domain registers.<br>\n",
    "* Customers registered using the junk email domain have the lowest success rate.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flagging the missing values by calling the user defined functionn mv_flagger\n",
    "mv_flagger(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the dataset where people have not given their family name\n",
    "original_df.loc[original_df['m_FAMILY_NAME']==1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The last name is missing as there is a parenthesis around it. The code considered it NaN coz of the parenthesis. The email id actually provides the last names.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the names and summing the number of resulting items\n",
    "text_split_feature(col = 'NAME',\n",
    "                   df  = original_df)\n",
    "\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the highest words in a particular name\n",
    "original_df['number_of_names'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the names that have 6 words\n",
    "original_df['NAME'][original_df['number_of_names']==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the names that have more than 3 words (assuming peple generally have one first, last and middle name)\n",
    "original_df['NAME'][original_df['number_of_names']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding the categorical variable 'DOMAIN_TYPE'\n",
    "one_hot_DOMAIN_TYPE  = pd.get_dummies(original_df['DOMAIN_TYPE'])\n",
    "\n",
    "#Joining the one-hot encoded columns to the apprentice_chef dataset\n",
    "original_df = original_df.join([one_hot_DOMAIN_TYPE])\n",
    "\n",
    "#Viewing the new dataset\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating histograms through seaborn's distplots to visually detect outliers\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(original_df['REVENUE'],\n",
    "             bins  = 'fd',\n",
    "             color = 'b')\n",
    "plt.xlabel(\"REVENUE\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(original_df['CROSS_SELL_SUCCESS'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel(\"CROSS_SELL_SUCCESS\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(original_df['TOTAL_MEALS_ORDERED'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel(\"TOTAL_MEALS_ORDERED\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(original_df['UNIQUE_MEALS_PURCH'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel(\"UNIQUE_MEALS_PURCH\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Apprentice Chef Data Histograms 1 of 7.png')\n",
    "plt.show()\n",
    "\n",
    "#####################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(original_df['CONTACTS_W_CUSTOMER_SERVICE'],\n",
    "             bins  = 'fd',\n",
    "             color = 'b')\n",
    "plt.xlabel(\"CONTACTS_W_CUSTOMER_SERVICE\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(original_df['PRODUCT_CATEGORIES_VIEWED'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel(\"PRODUCT_CATEGORIES_VIEWED\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(original_df['AVG_TIME_PER_SITE_VISIT'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel(\"AVG_TIME_PER_SITE_VISIT\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(original_df['MOBILE_NUMBER'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel(\"MOBILE_NUMBER\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Apprentice Chef Data Histograms 2 of 7.png')\n",
    "plt.show()\n",
    "\n",
    "#####################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(original_df['CANCELLATIONS_BEFORE_NOON'],\n",
    "             bins  = 'fd',\n",
    "             color = 'b')\n",
    "plt.xlabel(\"CANCELLATIONS_BEFORE_NOON\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(original_df['CANCELLATIONS_AFTER_NOON'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel(\"CANCELLATIONS_AFTER_NOON\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(original_df['TASTES_AND_PREFERENCES'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel(\"TASTES_AND_PREFERENCES\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(original_df['PC_LOGINS'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel(\"PC_LOGINS\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Apprentice Chef Data Histograms 3 of 7.png')\n",
    "plt.show()\n",
    "\n",
    "#####################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(original_df['MOBILE_LOGINS'],\n",
    "             bins  = 'fd',\n",
    "             color = 'b')\n",
    "plt.xlabel(\"MOBILE_LOGINS\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(original_df['WEEKLY_PLAN'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel(\"WEEKLY_PLAN\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(original_df['EARLY_DELIVERIES'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel(\"EARLY_DELIVERIES\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(original_df['LATE_DELIVERIES'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel(\"LATE_DELIVERIES\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Apprentice Chef Data Histograms 4 of 7.png')\n",
    "plt.show()\n",
    "\n",
    "#####################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(original_df['PACKAGE_LOCKER'],\n",
    "             bins  = 'fd',\n",
    "             color = 'b')\n",
    "plt.xlabel(\"PACKAGE_LOCKER\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(original_df['REFRIGERATED_LOCKER'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel(\"REFRIGERATED_LOCKER\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(original_df['FOLLOWED_RECOMMENDATIONS_PCT'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel(\"FOLLOWED_RECOMMENDATIONS_PCT\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(original_df['AVG_PREP_VID_TIME'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel(\"AVG_PREP_VID_TIME\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Apprentice Chef Data Histograms 5 of 7.png')\n",
    "plt.show()\n",
    "\n",
    "#####################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(original_df['LARGEST_ORDER_SIZE'],\n",
    "             bins  = 'fd',\n",
    "             color = 'b')\n",
    "plt.xlabel(\"LARGEST_ORDER_SIZE\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(original_df['MASTER_CLASSES_ATTENDED'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel(\"MASTER_CLASSES_ATTENDED\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(original_df['MEDIAN_MEAL_RATING'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel(\"MEDIAN_MEAL_RATING\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(original_df['AVG_CLICKS_PER_VISIT'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel(\"AVG_CLICKS_PER_VISIT\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Apprentice Chef Data Histograms 6 of 7.png')\n",
    "plt.show()\n",
    "\n",
    "#####################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "sns.distplot(original_df['TOTAL_PHOTOS_VIEWED'],\n",
    "             bins  = 'fd',\n",
    "             color = 'b')\n",
    "plt.xlabel(\"TOTAL_PHOTOS_VIEWED\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Apprentice Chef Data Histograms 7 of 7.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting outlier thresholds\n",
    "REVENUE_HI                       = 5800\n",
    "#CROSS_SELL_SUCCESS\n",
    "TOTAL_MEALS_ORDERED_HI           = 220\n",
    "UNIQUE_MEALS_PURCH_HI            = 9\n",
    "CONTACTS_W_CUSTOMER_SERVICE_LOW  = 3\n",
    "CONTACTS_W_CUSTOMER_SERVICE_HI   = 12.5\n",
    "PRODUCT_CATEGORIES_VIEWED_LOW    = 2\n",
    "PRODUCT_CATEGORIES_VIEWED_HI     = 10\n",
    "AVG_TIME_PER_SITE_VISIT_HI       = 200\n",
    "#MOBILE_NUMBER\n",
    "CANCELLATIONS_BEFORE_NOON_HI     = 5\n",
    "CANCELLATIONS_AFTER_NOON_HI      = 2\n",
    "#TASTES_AND_PREFERENCES\n",
    "PC_LOGINS_LOW                    = 5\n",
    "PC_LOGINS_HI                     = 6\n",
    "MOBILE_LOGINS_LOW                = 1\n",
    "MOBILE_LOGINS_HI                 = 2\n",
    "WEEKLY_PLAN_HI                   = 15\n",
    "EARLY_DELIVERIES_HI              = 4\n",
    "LATE_DELIVERIES_HI               = 10\n",
    "#PACKAGE_LOCKER\n",
    "#REFRIGERATED_LOCKER\n",
    "FOLLOWED_RECOMMENDATIONS_PCT_LOW = 10\n",
    "FOLLOWED_RECOMMENDATIONS_PCT_HI  = 70\n",
    "AVG_PREP_VID_TIME_LOW            = 70\n",
    "AVG_PREP_VID_TIME_HI             = 280\n",
    "LARGEST_ORDER_SIZE_LOW           = 2\n",
    "LARGEST_ORDER_SIZE_HI            = 8\n",
    "MASTER_CLASSES_ATTENDED_HI       = 1\n",
    "MEDIAN_MEAL_RATING_LOW           = 2\n",
    "MEDIAN_MEAL_RATING_HI            = 4\n",
    "AVG_CLICKS_PER_VISIT_LOW         = 8\n",
    "AVG_CLICKS_PER_VISIT_HI          = 17.5\n",
    "TOTAL_PHOTOS_VIEWED_HI           = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new features (columns) for outliers\n",
    "#REVENUE\n",
    "original_df['out_REVENUE'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_REVENUE'][original_df['REVENUE'] > REVENUE_HI]\n",
    "\n",
    "original_df['out_REVENUE'].replace(to_replace = condition_hi,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "#TOTAL_MEALS_ORDERED\n",
    "original_df['out_TOTAL_MEALS_ORDERED'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_MEALS_ORDERED'][original_df['TOTAL_MEALS_ORDERED'] > TOTAL_MEALS_ORDERED_HI]\n",
    "\n",
    "original_df['out_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                               value      = 1,\n",
    "                                               inplace    = True)\n",
    "\n",
    "#UNIQUE_MEALS_PURCH\n",
    "original_df['out_UNIQUE_MEALS_PURCH'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_UNIQUE_MEALS_PURCH'][original_df['UNIQUE_MEALS_PURCH'] > UNIQUE_MEALS_PURCH_HI]\n",
    "\n",
    "original_df['out_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "\n",
    "#CONTACTS_W_CUSTOMER_SERVICE\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][original_df['CONTACTS_W_CUSTOMER_SERVICE'] > CONTACTS_W_CUSTOMER_SERVICE_HI]\n",
    "condition_lo = original_df.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][original_df['CONTACTS_W_CUSTOMER_SERVICE'] < CONTACTS_W_CUSTOMER_SERVICE_LOW]\n",
    "\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                                       value      = 1,\n",
    "                                                       inplace    = True)\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_lo,\n",
    "                                                       value      = 1,\n",
    "                                                       inplace    = True)\n",
    "\n",
    "#PRODUCT_CATEGORIES_VIEWED\n",
    "original_df['out_PRODUCT_CATEGORIES_VIEWED'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_PRODUCT_CATEGORIES_VIEWED'][original_df['PRODUCT_CATEGORIES_VIEWED'] > PRODUCT_CATEGORIES_VIEWED_HI]\n",
    "condition_lo = original_df.loc[0:,'out_PRODUCT_CATEGORIES_VIEWED'][original_df['PRODUCT_CATEGORIES_VIEWED'] < PRODUCT_CATEGORIES_VIEWED_LOW]\n",
    "\n",
    "original_df['out_PRODUCT_CATEGORIES_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                                     value      = 1,\n",
    "                                                     inplace    = True)\n",
    "original_df['out_PRODUCT_CATEGORIES_VIEWED'].replace(to_replace = condition_lo,\n",
    "                                                     value      = 1,\n",
    "                                                     inplace    = True)\n",
    "\n",
    "#AVG_TIME_PER_SITE_VISIT\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_AVG_TIME_PER_SITE_VISIT'][original_df['AVG_TIME_PER_SITE_VISIT'] > AVG_TIME_PER_SITE_VISIT_HI]\n",
    "\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                                   value      = 1,\n",
    "                                                   inplace    = True)\n",
    "\n",
    "#CANCELLATIONS_BEFORE_NOON\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_CANCELLATIONS_BEFORE_NOON'][original_df['CANCELLATIONS_BEFORE_NOON'] > CANCELLATIONS_BEFORE_NOON_HI]\n",
    "\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                                     value      = 1,\n",
    "                                                     inplace    = True)\n",
    "\n",
    "#CANCELLATIONS_AFTER_NOON\n",
    "original_df['out_CANCELLATIONS_AFTER_NOON'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_CANCELLATIONS_AFTER_NOON'][original_df['CANCELLATIONS_AFTER_NOON'] > CANCELLATIONS_AFTER_NOON_HI]\n",
    "\n",
    "original_df['out_CANCELLATIONS_AFTER_NOON'].replace(to_replace = condition_hi,\n",
    "                                                    value      = 1,\n",
    "                                                    inplace    = True)\n",
    "\n",
    "#PC_LOGINS\n",
    "original_df['out_PC_LOGINS'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_PC_LOGINS'][original_df['PC_LOGINS'] > PC_LOGINS_HI]\n",
    "condition_lo = original_df.loc[0:,'out_PC_LOGINS'][original_df['PC_LOGINS'] < PC_LOGINS_LOW]\n",
    "\n",
    "original_df['out_PC_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                     value      = 1,\n",
    "                                     inplace    = True)\n",
    "original_df['out_PC_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                     value      = 1,\n",
    "                                     inplace    = True)\n",
    "\n",
    "#MOBILE_LOGINS\n",
    "original_df['out_MOBILE_LOGINS'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_MOBILE_LOGINS'][original_df['MOBILE_LOGINS'] > MOBILE_LOGINS_HI]\n",
    "condition_lo = original_df.loc[0:,'out_MOBILE_LOGINS'][original_df['MOBILE_LOGINS'] < MOBILE_LOGINS_LOW]\n",
    "\n",
    "original_df['out_MOBILE_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                         value      = 1,\n",
    "                                         inplace    = True)\n",
    "original_df['out_MOBILE_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                         value      = 1,\n",
    "                                         inplace    = True)\n",
    "\n",
    "#WEEKLY_PLAN\n",
    "original_df['out_WEEKLY_PLAN'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_WEEKLY_PLAN'][original_df['WEEKLY_PLAN'] > WEEKLY_PLAN_HI]\n",
    "\n",
    "original_df['out_WEEKLY_PLAN'].replace(to_replace = condition_hi,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "#EARLY_DELIVERIES\n",
    "original_df['out_EARLY_DELIVERIES'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_EARLY_DELIVERIES'][original_df['EARLY_DELIVERIES'] > EARLY_DELIVERIES_HI]\n",
    "\n",
    "original_df['out_EARLY_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                            value      = 1,\n",
    "                                            inplace    = True)\n",
    "\n",
    "#LATE_DELIVERIES\n",
    "original_df['out_LATE_DELIVERIES'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_LATE_DELIVERIES'][original_df['LATE_DELIVERIES'] > LATE_DELIVERIES_HI]\n",
    "\n",
    "original_df['out_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "\n",
    "#FOLLOWED_RECOMMENDATIONS_PCT\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][original_df['FOLLOWED_RECOMMENDATIONS_PCT'] > FOLLOWED_RECOMMENDATIONS_PCT_HI]\n",
    "condition_lo = original_df.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][original_df['FOLLOWED_RECOMMENDATIONS_PCT'] < FOLLOWED_RECOMMENDATIONS_PCT_LOW]\n",
    "\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_hi,\n",
    "                                                        value      = 1,\n",
    "                                                        inplace    = True)\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_lo,\n",
    "                                                        value      = 1,\n",
    "                                                        inplace    = True)\n",
    "\n",
    "#AVG_PREP_VID_TIME\n",
    "original_df['out_AVG_PREP_VID_TIME'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_AVG_PREP_VID_TIME'][original_df['AVG_PREP_VID_TIME'] > AVG_PREP_VID_TIME_HI]\n",
    "condition_lo = original_df.loc[0:,'out_AVG_PREP_VID_TIME'][original_df['AVG_PREP_VID_TIME'] < AVG_PREP_VID_TIME_LOW]\n",
    "\n",
    "original_df['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                             value      = 1,\n",
    "                                             inplace    = True)\n",
    "original_df['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_lo,\n",
    "                                             value      = 1,\n",
    "                                             inplace    = True)\n",
    "\n",
    "#LARGEST_ORDER_SIZE\n",
    "original_df['out_LARGEST_ORDER_SIZE'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_LARGEST_ORDER_SIZE'][original_df['LARGEST_ORDER_SIZE'] > LARGEST_ORDER_SIZE_HI]\n",
    "condition_lo = original_df.loc[0:,'out_LARGEST_ORDER_SIZE'][original_df['LARGEST_ORDER_SIZE'] < LARGEST_ORDER_SIZE_LOW]\n",
    "\n",
    "original_df['out_LARGEST_ORDER_SIZE'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "original_df['out_LARGEST_ORDER_SIZE'].replace(to_replace = condition_lo,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "\n",
    "#MASTER_CLASSES_ATTENDED\n",
    "original_df['out_MASTER_CLASSES_ATTENDED'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_MASTER_CLASSES_ATTENDED'][original_df['MASTER_CLASSES_ATTENDED'] > MASTER_CLASSES_ATTENDED_HI]\n",
    "\n",
    "original_df['out_MASTER_CLASSES_ATTENDED'].replace(to_replace = condition_hi,\n",
    "                                                   value      = 1,\n",
    "                                                   inplace    = True)\n",
    "\n",
    "#MEDIAN_MEAL_RATING\n",
    "original_df['out_MEDIAN_MEAL_RATING'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_MEDIAN_MEAL_RATING'][original_df['MEDIAN_MEAL_RATING'] > MEDIAN_MEAL_RATING_HI]\n",
    "condition_lo = original_df.loc[0:,'out_MEDIAN_MEAL_RATING'][original_df['MEDIAN_MEAL_RATING'] < MEDIAN_MEAL_RATING_LOW]\n",
    "\n",
    "original_df['out_MEDIAN_MEAL_RATING'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "original_df['out_MEDIAN_MEAL_RATING'].replace(to_replace = condition_lo,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "\n",
    "#AVG_CLICKS_PER_VISIT\n",
    "original_df['out_AVG_CLICKS_PER_VISIT'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_AVG_CLICKS_PER_VISIT'][original_df['AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_HI]\n",
    "condition_lo = original_df.loc[0:,'out_AVG_CLICKS_PER_VISIT'][original_df['AVG_CLICKS_PER_VISIT'] < AVG_CLICKS_PER_VISIT_LOW]\n",
    "\n",
    "original_df['out_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_hi,\n",
    "                                                value      = 1,\n",
    "                                                inplace    = True)\n",
    "original_df['out_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_lo,\n",
    "                                                value      = 1,\n",
    "                                                inplace    = True)\n",
    "\n",
    "#TOTAL_PHOTOS_VIEWED\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED'] = 0 #initializing the column\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_PHOTOS_VIEWED'][original_df['TOTAL_PHOTOS_VIEWED'] > TOTAL_PHOTOS_VIEWED_HI]\n",
    "\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                               value      = 1,\n",
    "                                               inplace    = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the new dataset with the outlier features\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the already encoded variables from the dataset\n",
    "original_df = original_df.drop(['NAME', 'FIRST_NAME', 'FAMILY_NAME', 'EMAIL', 'EMAIL_DOMAIN', 'DOMAIN_TYPE'], axis = 1)\n",
    "\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the feature rich dataset to excel\n",
    "original_df.to_excel('apprentice_chef_feature_rich.xlsx',\n",
    "                         index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the top 10 positively correlated explanatory variables with the target variable\n",
    "original_df_corr = original_df.corr().round(2)\n",
    "original_df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the top 10 negatively correlated explanatory variables with the target variable\n",
    "original_df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False).tail(n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Further to insight one, we see that junk email domain have a very high negative correlation with cross sell success.\n",
    "Meaning more people that register with these email domains are less likely to opt for the cross selling promotion of wine bottle. These email domains, most probably taken out of use by the companies, due to shifting into a new email domain, are most likely used by people that are not very active at checking their mails in this address.\n",
    "\n",
    "<h6>Insight 2</h6>\n",
    "People who follow meal recommendation, that is displayed on the web or mobile platform, are very likely to subscribe to the cross selling promotion, as shown by the high positive correlation. \n",
    "\n",
    "From insight 1 and 2, could it be beneficial if Halfway there is promoted more aggressively to people who register with their professional email addresses and to the ones that repeatedly follow the meal recommendation? Could the meal recommendations be tailored to the professionals in a way, such that those recommended meals are the ones that compliment the wine better?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap 1\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "#original_df_corr1 = original_df.corr().round(2).iloc[0:19, 0:19]\n",
    "\n",
    "#sns.heatmap(original_df_corr1,\n",
    "#            cmap       = 'coolwarm',\n",
    "#            square     = True,\n",
    "#            annot      = True,\n",
    "#            linecolor  = 'black',\n",
    "#            linewidths = 0.5)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "original_df_corr2 = original_df.corr().round(2).iloc[20:39, 20:39]\n",
    "\n",
    "sns.heatmap(original_df_corr2,\n",
    "            cmap       = 'coolwarm',\n",
    "            square     = True,\n",
    "            annot      = True,\n",
    "            linecolor  = 'black',\n",
    "            linewidths = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "As seen from the correlation plot, median meal rating is very negatively correlated with average clicks per visit (-0.86). Probably people that click many times are not finding what they are looking for and hence end up giving a poor meal rating. Some thing that the recommendation engine design should take care of.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap 3\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "#original_df_corr3 = original_df.corr().round(2).iloc[40:50, 40:50]\n",
    "\n",
    "#sns.heatmap(original_df_corr3,\n",
    "#            cmap       = 'coolwarm',\n",
    "#            square     = True,\n",
    "#            annot      = True,\n",
    "#            linecolor  = 'black',\n",
    "#            linewidths = 0.5)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br><h2>Modeling</h2><br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring the explanatory variables\n",
    "original_df_data = original_df.drop('CROSS_SELL_SUCCESS', axis = 1)\n",
    "\n",
    "#Declaring the target variable\n",
    "original_df_target = original_df.loc[:, 'CROSS_SELL_SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(original_df_data,\n",
    "                                                    original_df_target,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 222,\n",
    "                                                    stratify = original_df_target)\n",
    "\n",
    "\n",
    "#Exploring the dimensions of training set \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#Exploring the dimensions of testing set\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Creating a base model between the target variable and the highly correlated explanatory variable\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a logistic regression model object \n",
    "logistic_small = smf.logit(formula   = \"\"\"CROSS_SELL_SUCCESS ~ FOLLOWED_RECOMMENDATIONS_PCT\"\"\",\n",
    "                           data = original_df)\n",
    "\n",
    "\n",
    "#FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "#Checking the results SUMMARY\n",
    "results_logistic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Creating a Logistic Regression model using statsmodel, with all the explanatory variables\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for val in original_df_data:\n",
    "#    print(f\"{val} +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\"CROSS_SELL_SUCCESS ~ REVENUE +\n",
    "                                                            TOTAL_MEALS_ORDERED +\n",
    "                                                            UNIQUE_MEALS_PURCH +\n",
    "                                                            CONTACTS_W_CUSTOMER_SERVICE +\n",
    "                                                            PRODUCT_CATEGORIES_VIEWED +\n",
    "                                                            AVG_TIME_PER_SITE_VISIT +\n",
    "                                                            MOBILE_NUMBER +\n",
    "                                                            CANCELLATIONS_BEFORE_NOON +\n",
    "                                                            CANCELLATIONS_AFTER_NOON +\n",
    "                                                            TASTES_AND_PREFERENCES +\n",
    "                                                            PC_LOGINS +\n",
    "                                                            MOBILE_LOGINS +\n",
    "                                                            WEEKLY_PLAN +\n",
    "                                                            EARLY_DELIVERIES +\n",
    "                                                            LATE_DELIVERIES +\n",
    "                                                            PACKAGE_LOCKER +\n",
    "                                                            REFRIGERATED_LOCKER +\n",
    "                                                            FOLLOWED_RECOMMENDATIONS_PCT +\n",
    "                                                            AVG_PREP_VID_TIME +\n",
    "                                                            LARGEST_ORDER_SIZE +\n",
    "                                                            MASTER_CLASSES_ATTENDED +\n",
    "                                                            MEDIAN_MEAL_RATING +\n",
    "                                                            AVG_CLICKS_PER_VISIT +\n",
    "                                                            TOTAL_PHOTOS_VIEWED +\n",
    "                                                            m_FAMILY_NAME +\n",
    "                                                            number_of_names +\n",
    "                                                            junk +\n",
    "                                                            personal +\n",
    "                                                            professional +\n",
    "                                                            out_REVENUE +\n",
    "                                                            out_TOTAL_MEALS_ORDERED +\n",
    "                                                            out_UNIQUE_MEALS_PURCH +\n",
    "                                                            out_CONTACTS_W_CUSTOMER_SERVICE +\n",
    "                                                            out_PRODUCT_CATEGORIES_VIEWED +\n",
    "                                                            out_AVG_TIME_PER_SITE_VISIT +\n",
    "                                                            out_CANCELLATIONS_BEFORE_NOON +\n",
    "                                                            out_CANCELLATIONS_AFTER_NOON +\n",
    "                                                            out_PC_LOGINS +\n",
    "                                                            out_MOBILE_LOGINS +\n",
    "                                                            out_WEEKLY_PLAN +\n",
    "                                                            out_EARLY_DELIVERIES +\n",
    "                                                            out_LATE_DELIVERIES +\n",
    "                                                            out_FOLLOWED_RECOMMENDATIONS_PCT +\n",
    "                                                            out_AVG_PREP_VID_TIME +\n",
    "                                                            out_LARGEST_ORDER_SIZE +\n",
    "                                                            out_MASTER_CLASSES_ATTENDED +\n",
    "                                                            out_MEDIAN_MEAL_RATING +\n",
    "                                                            out_AVG_CLICKS_PER_VISIT +\n",
    "                                                            out_TOTAL_PHOTOS_VIEWED\"\"\",\n",
    "                                                            data = original_df)\n",
    "\n",
    "#Fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "#Displaying the results\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a model with just the significant variables (p-value less than 0.05)\n",
    "#Instantiating a logistic regression model object\n",
    "logistic_sig = smf.logit(formula = \"\"\"CROSS_SELL_SUCCESS ~ MOBILE_NUMBER +\n",
    "                                                           CANCELLATIONS_BEFORE_NOON +\n",
    "                                                           CANCELLATIONS_AFTER_NOON +\n",
    "                                                           TASTES_AND_PREFERENCES +\n",
    "                                                           PC_LOGINS +\n",
    "                                                           MOBILE_LOGINS +\n",
    "                                                           REFRIGERATED_LOCKER +\n",
    "                                                           FOLLOWED_RECOMMENDATIONS_PCT +\n",
    "                                                           number_of_names +\n",
    "                                                           personal +\n",
    "                                                           professional +\n",
    "                                                           out_CONTACTS_W_CUSTOMER_SERVICE +\n",
    "                                                           out_FOLLOWED_RECOMMENDATIONS_PCT\"\"\",\n",
    "                                                           data = original_df)\n",
    "\n",
    "#Fitting the model object\n",
    "results_full = logistic_sig.fit()\n",
    "\n",
    "#Displaying the results\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variables that were discarded in order of their high p-value\n",
    "#junk\n",
    "#out_CANCELLATIONS_AFTER_NOON +\n",
    "#UNIQUE_MEALS_PURCH +\n",
    "#out_MASTER_CLASSES_ATTENDED +\n",
    "#MEDIAN_MEAL_RATING +\n",
    "#out_EARLY_DELIVERIES\n",
    "#PRODUCT_CATEGORIES_VIEWED +\n",
    "#out_UNIQUE_MEALS_PURCH +\n",
    "#PACKAGE_LOCKER +\n",
    "#MASTER_CLASSES_ATTENDED +\n",
    "#out_MOBILE_LOGINS +\n",
    "#CONTACTS_W_CUSTOMER_SERVICE +\n",
    "#LATE_DELIVERIES +\n",
    "#LARGEST_ORDER_SIZE +\n",
    "#WEEKLY_PLAN +\n",
    "#out_CANCELLATIONS_BEFORE_NOON +\n",
    "#TOTAL_PHOTOS_VIEWED +\n",
    "#out_MEDIAN_MEAL_RATING +\n",
    "#out_REVENUE + +\n",
    "#out_TOTAL_PHOTOS_VIEWED\n",
    "#AVG_PREP_VID_TIME ++\n",
    "#out_AVG_CLICKS_PER_VISIT +\n",
    "#out_LARGEST_ORDER_SIZE\n",
    "#out_PRODUCT_CATEGORIES_VIEWED +\n",
    "#out_PC_LOGINS +\n",
    "#out_LATE_DELIVERIES +\n",
    "#out_AVG_TIME_PER_SITE_VISIT +\n",
    "#out_WEEKLY_PLAN +\n",
    "#AVG_TIME_PER_SITE_VISIT +\n",
    "#m_FAMILY_NAME +\n",
    "##out_TOTAL_MEALS_ORDERED +\n",
    "#TOTAL_MEALS_ORDERED + +\n",
    "#out_AVG_PREP_VID_TIME\n",
    "#REVENUE +\n",
    "#AVG_CLICKS_PER_VISIT +\n",
    "#EARLY_DELIVERIES +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " #Full model\n",
    " 'logit_full'   : [ 'REVENUE', \n",
    "                    'TOTAL_MEALS_ORDERED', \n",
    "                    'UNIQUE_MEALS_PURCH', \n",
    "                    'CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                    'PRODUCT_CATEGORIES_VIEWED', \n",
    "                    'AVG_TIME_PER_SITE_VISIT', \n",
    "                    'MOBILE_NUMBER', \n",
    "                    'CANCELLATIONS_BEFORE_NOON', \n",
    "                    'CANCELLATIONS_AFTER_NOON', \n",
    "                    'TASTES_AND_PREFERENCES', \n",
    "                    'PC_LOGINS', \n",
    "                    'MOBILE_LOGINS', \n",
    "                    'WEEKLY_PLAN', \n",
    "                    'EARLY_DELIVERIES', \n",
    "                    'LATE_DELIVERIES', \n",
    "                    'PACKAGE_LOCKER', \n",
    "                    'REFRIGERATED_LOCKER', \n",
    "                    'FOLLOWED_RECOMMENDATIONS_PCT', \n",
    "                    'AVG_PREP_VID_TIME', \n",
    "                    'LARGEST_ORDER_SIZE', \n",
    "                    'MASTER_CLASSES_ATTENDED', \n",
    "                    'MEDIAN_MEAL_RATING', \n",
    "                    'AVG_CLICKS_PER_VISIT', \n",
    "                    'TOTAL_PHOTOS_VIEWED', \n",
    "                    'm_FAMILY_NAME', \n",
    "                    'number_of_names', \n",
    "                    'junk', \n",
    "                    'personal', \n",
    "                    'professional', \n",
    "                    'out_REVENUE', \n",
    "                    'out_TOTAL_MEALS_ORDERED', \n",
    "                    'out_UNIQUE_MEALS_PURCH', \n",
    "                    'out_CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                    'out_PRODUCT_CATEGORIES_VIEWED', \n",
    "                    'out_AVG_TIME_PER_SITE_VISIT', \n",
    "                    'out_CANCELLATIONS_BEFORE_NOON', \n",
    "                    'out_CANCELLATIONS_AFTER_NOON', \n",
    "                    'out_PC_LOGINS', \n",
    "                    'out_MOBILE_LOGINS', \n",
    "                    'out_WEEKLY_PLAN', \n",
    "                    'out_EARLY_DELIVERIES', \n",
    "                    'out_LATE_DELIVERIES', \n",
    "                    'out_FOLLOWED_RECOMMENDATIONS_PCT', \n",
    "                    'out_AVG_PREP_VID_TIME', \n",
    "                    'out_LARGEST_ORDER_SIZE', \n",
    "                    'out_MASTER_CLASSES_ATTENDED', \n",
    "                    'out_MEDIAN_MEAL_RATING', \n",
    "                    'out_AVG_CLICKS_PER_VISIT', \n",
    "                    'out_TOTAL_PHOTOS_VIEWED'],\n",
    " \n",
    " #Significant variables only\n",
    " 'logit_sig'    : ['MOBILE_NUMBER',\n",
    "                   'CANCELLATIONS_BEFORE_NOON', \n",
    "                   'CANCELLATIONS_AFTER_NOON',\n",
    "                   'TASTES_AND_PREFERENCES',\n",
    "                   'PC_LOGINS', \n",
    "                   'MOBILE_LOGINS', \n",
    "                   'REFRIGERATED_LOCKER', \n",
    "                   'FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "                   'number_of_names', \n",
    "                   'personal',\n",
    "                   'professional', \n",
    "                   'out_CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                   'out_FOLLOWED_RECOMMENDATIONS_PCT']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing candidate variable sets\n",
    "print(f\"\"\"\n",
    "/--------------------------\\\\\n",
    "|Explanatory Variable Sets |\n",
    "\\\\--------------------------/\n",
    "\n",
    "Full Model:\n",
    "-----------\n",
    "{candidate_dict['logit_full']}\n",
    "\n",
    "\n",
    "Significant p-value Model:\n",
    "--------------------------\n",
    "{candidate_dict['logit_sig']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Building a Logistic Regression model</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the significant variables as explanatory variables\n",
    "original_df_data   =  original_df.loc[ : , candidate_dict['logit_sig']]\n",
    "\n",
    "\n",
    "#Conducting the train test split with the new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(original_df_data,\n",
    "                                                    original_df_target,\n",
    "                                                    random_state = 222,\n",
    "                                                    test_size    = 0.25,\n",
    "                                                    stratify     = original_df_target)\n",
    "\n",
    "\n",
    "#INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 222)\n",
    "\n",
    "\n",
    "#FITTING the training data\n",
    "logreg_fit = logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(X_test, y_test).round(4))\n",
    "print('ROC_AUC_SCORE    :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = logreg_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the confusion matrix for LogisticRegression\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))\n",
    "\n",
    "visual_cm(true_y = y_test,\n",
    "          pred_y = logreg_pred,\n",
    "          labels = ['Not subscribed', 'Subscribed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Saving the model performances for future comparisons\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an empty list\n",
    "model_performance = [['Model', 'Training Accuracy',\n",
    "                      'Testing Accuracy', 'AUC Value']]\n",
    "\n",
    "\n",
    "#Training accuracy of LogisticRegression model\n",
    "logreg_train_acc  = logreg_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "\n",
    "#Training accuracy of LogisticRegression model\n",
    "logreg_test_acc   = logreg_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "#ROC AUC value of LogisticRegression model\n",
    "logreg_auc = roc_auc_score(y_true  = y_test,\n",
    "                           y_score = logreg_pred).round(4)\n",
    "\n",
    "\n",
    "#Saving the results\n",
    "model_performance.append(['Logistic Regression',\n",
    "                          logreg_train_acc,\n",
    "                          logreg_test_acc,\n",
    "                          logreg_auc])\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Building a KNN model</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the pre-defined function to find the optimal neighbors\n",
    "opt_neighbors = optimal_neighbors(X_data = original_df_data,\n",
    "                                  y_data = original_df_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Scaling the explanatory data using Standard Scaler and building a KNN model\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "#FITTING the data\n",
    "scaler.fit(original_df_data)\n",
    "\n",
    "\n",
    "#TRANSFORMING the data\n",
    "X_scaled     = scaler.transform(original_df_data)\n",
    "\n",
    "\n",
    "#Converting to a DataFrame\n",
    "X_scaled_df  = pd.DataFrame(X_scaled) \n",
    "\n",
    "\n",
    "#Train-test split with the scaled data\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled_df,\n",
    "                                                                  original_df_target,\n",
    "                                                                  random_state = 222,\n",
    "                                                                  test_size    = 0.25,\n",
    "                                                                  stratify     = original_df_target)\n",
    "\n",
    "\n",
    "#INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "#FITTING the training data\n",
    "knn_fit = knn_opt.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(X_train_scaled, y_train).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(X_test_scaled, y_test).round(4))\n",
    "print('ROC AUC Score    :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the confusion matrix for KNN\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = knn_pred))\n",
    "\n",
    "visual_cm(true_y = y_test,\n",
    "          pred_y = knn_pred,\n",
    "          labels = ['Not subscribed', 'Subscribed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Saving the model performances for future comparisons\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training accuracy of a scaled KNN model\n",
    "knn_train_acc  = knn_fit.score(X_train_scaled, y_train).round(4)\n",
    "\n",
    "\n",
    "#Testing accuracy of a scaled KNN model\n",
    "knn_test_acc   = knn_fit.score(X_test_scaled, y_test).round(4)\n",
    "\n",
    "\n",
    "#ROC AUC value of a scaled KNN model\n",
    "knn_auc = roc_auc_score(y_true  = y_test,\n",
    "                        y_score = knn_pred).round(4)\n",
    "\n",
    "\n",
    "#Saving the results\n",
    "model_performance.append(['Scaled KNN Classification',\n",
    "                          knn_train_acc,\n",
    "                          knn_test_acc,\n",
    "                          knn_auc])\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Building a Pruned Classification Tree model</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING a classification tree object\n",
    "tree_pruned      = DecisionTreeClassifier(max_depth = 4,\n",
    "                                          min_samples_leaf = 25,\n",
    "                                          random_state = 222)\n",
    "\n",
    "\n",
    "#FITTING the training data\n",
    "tree_pruned_fit  = tree_pruned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING on new data\n",
    "tree_pred = tree_pruned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pred).round(4))\n",
    "\n",
    "\n",
    "#Calling display_tree\n",
    "display_tree(tree       = tree_pruned_fit,\n",
    "             feature_df = X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting feature importance\n",
    "plot_feature_importances(tree_pruned_fit,\n",
    "                         train = X_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Saving the model performances for future comparisons\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train accuracy of Pruned Tree\n",
    "pruned_tree_train_acc = tree_pruned_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "\n",
    "#Test accuracy of Pruned Tree\n",
    "pruned_tree_test_acc  = tree_pruned_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "#ROC AUC value\n",
    "pruned_tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = tree_pred).round(4)\n",
    "\n",
    "\n",
    "#Saving the results\n",
    "model_performance.append(['Pruned Tree',\n",
    "                          pruned_tree_train_acc,\n",
    "                          pruned_tree_test_acc,\n",
    "                          pruned_tree_auc])\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Hyperparameter tuning on Logistic Regression model using GridSearchCV</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring a hyperparameter space\n",
    "C_space          = pd.np.arange(0.1, 3.0, 0.1)\n",
    "warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "#Creating a hyperparameter grid\n",
    "param_grid = {'C'          : C_space,\n",
    "              'warm_start' : warm_start_space}\n",
    "\n",
    "\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(solver = 'lbfgs',\n",
    "                              random_state = 222)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "lr_tuned_cv = GridSearchCV(estimator  = lr_tuned,\n",
    "                           param_grid = param_grid,\n",
    "                           cv         = 3,\n",
    "                           scoring    = make_scorer(roc_auc_score,\n",
    "                                                    needs_threshold = False))\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "lr_tuned_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "\n",
    "#Printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a model based on hyperparameter tuning results\n",
    "\n",
    "#Using the significant variables as explanatory variables\n",
    "original_df_data   =  original_df.loc[ : , candidate_dict['logit_sig']]\n",
    "\n",
    "\n",
    "#Conducting the train test split with the new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(original_df_data,\n",
    "                                                    original_df_target,\n",
    "                                                    random_state = 222,\n",
    "                                                    test_size    = 0.25,\n",
    "                                                    stratify     = original_df_target)\n",
    "\n",
    "#INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = lr_tuned_cv.best_estimator_\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the results\n",
    "print('Training ACCURACY:', lr_tuned.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_tuned.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(X_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(X_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#Appending to model_performance\n",
    "model_performance.append(['Tuned Logistic Regression',\n",
    "                           lr_train_acc,\n",
    "                           lr_test_acc,\n",
    "                           lr_auc])\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Hyperparameter tuning on Classification Tree with GridSearchCV</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring a hyperparameter space\n",
    "criterion_space = ['gini', 'entropy']\n",
    "splitter_space  = ['best', 'random']\n",
    "depth_space     = pd.np.arange(1, 25)\n",
    "leaf_space      = pd.np.arange(1, 100)\n",
    "\n",
    "\n",
    "#Creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_space,\n",
    "              'splitter'         : splitter_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 222)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "tuned_tree_cv = GridSearchCV(estimator  = tuned_tree,\n",
    "                             param_grid = param_grid,\n",
    "                             cv         = 3,\n",
    "                             scoring    = make_scorer(roc_auc_score,\n",
    "                                                      needs_threshold = False))\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "\n",
    "#Printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))\n",
    "\n",
    "#Tuned Parameters  : {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 9, 'splitter': 'random'}\n",
    "#Tuned Training AUC: 0.6707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a model based on hyperparameter tuning results\n",
    "\n",
    "#INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = tuned_tree_cv.best_estimator_\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(X_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(X_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                               y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#Appending to model_performance\n",
    "model_performance.append(['Tuned Tree',\n",
    "                           tree_train_acc,\n",
    "                           tree_test_acc,\n",
    "                           tree_auc])\n",
    "\n",
    "\n",
    "#Checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the tree\n",
    "display_tree(tree       = tree_tuned,\n",
    "             feature_df = original_df_data,\n",
    "             height     = 2000,\n",
    "             width      = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Building a Random forest model on significant explanatory variables</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 10,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 222)\n",
    "\n",
    "#FITTING the training data\n",
    "rf_default_fit = rf_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the important features\n",
    "plot_feature_importances(rf_default_fit,\n",
    "                         train = X_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(X_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(X_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "#Appending to model_performance\n",
    "model_performance.append(['Random Forest Default Parameters',\n",
    "                          rf_train_acc,\n",
    "                          rf_test_acc,\n",
    "                          rf_auc])\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Building a Random forest model with tuned parameters using GridSearchCV</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring a hyperparameter space\n",
    "estimator_space  = pd.np.arange(100, 1100, 250)\n",
    "leaf_space       = pd.np.arange(1, 31, 10)\n",
    "criterion_space  = ['gini', 'entropy']\n",
    "bootstrap_space  = [True, False]\n",
    "warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "#Creating a hyperparameter grid\n",
    "param_grid = {'n_estimators'     : estimator_space,\n",
    "              'min_samples_leaf' : leaf_space,\n",
    "              'criterion'        : criterion_space,\n",
    "              'bootstrap'        : bootstrap_space,\n",
    "              'warm_start'       : warm_start_space}\n",
    "\n",
    "\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "full_forest_grid = RandomForestClassifier(random_state = 222)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "full_forest_cv = GridSearchCV(estimator  = full_forest_grid,\n",
    "                              param_grid = param_grid,\n",
    "                              cv         = 3,\n",
    "                              scoring    = make_scorer(roc_auc_score,\n",
    "                                           needs_threshold = False))\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "full_forest_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", full_forest_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", full_forest_cv.best_score_.round(4))\n",
    "\n",
    "#Tuned Parameters  : {'bootstrap': False, 'criterion': 'entropy', 'min_samples_leaf': 1, 'n_estimators': 600, 'warm_start': True}\n",
    "#Tuned Training AUC: 0.6264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING the model object with hyperparameters\n",
    "full_rf_tuned = RandomForestClassifier(bootstrap        = True,\n",
    "                                       criterion        = 'gini',\n",
    "                                       min_samples_leaf = 1,\n",
    "                                       n_estimators     = 100,\n",
    "                                       warm_start       = True,\n",
    "                                       random_state     = 222)\n",
    "\n",
    "\n",
    "#FIT step is needed as we are not using .best_estimator\n",
    "full_rf_tuned_fit = full_rf_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "full_rf_tuned_pred = full_rf_tuned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the results\n",
    "print('Training ACCURACY:', full_rf_tuned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', full_rf_tuned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_rf_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring model performance objects\n",
    "rf_train_acc = full_rf_tuned_fit.score(X_train, y_train).round(4)\n",
    "rf_test_acc  = full_rf_tuned_fit.score(X_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = full_rf_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#Appending to model_performance\n",
    "model_performance.append(['Tuned Random Forest',\n",
    "                           rf_train_acc,\n",
    "                           rf_test_acc,\n",
    "                           rf_auc])\n",
    "\n",
    "\n",
    "#Checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Gradient Boosted Machines model with default parameters</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 222)\n",
    "\n",
    "\n",
    "#FITTING to the training data\n",
    "full_gbm_default_fit = full_gbm_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(X_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring model performance objects\n",
    "gbm_train_acc = full_gbm_default_fit.score(X_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(X_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "#Appending to model_performance\n",
    "model_performance.append(['GBM default parameters',\n",
    "                           gbm_train_acc,\n",
    "                           gbm_test_acc,\n",
    "                           gbm_auc])\n",
    "\n",
    "\n",
    "#Checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Gradient Boosted Machines model with tuned parameters</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring a hyperparameter space\n",
    "learn_space     = pd.np.arange(0.1, 1.6, 0.3)\n",
    "estimator_space = pd.np.arange(50, 250, 50)\n",
    "depth_space     = pd.np.arange(1, 10)\n",
    "\n",
    "\n",
    "#Creating a hyperparameter grid\n",
    "param_grid = {'learning_rate' : learn_space,\n",
    "              'max_depth'     : depth_space,\n",
    "              'n_estimators'  : estimator_space}\n",
    "\n",
    "\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_grid = GradientBoostingClassifier(random_state = 222)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "full_gbm_cv = GridSearchCV(estimator  = full_gbm_grid,\n",
    "                           param_grid = param_grid,\n",
    "                           cv         = 3,\n",
    "                           scoring    = make_scorer(roc_auc_score,\n",
    "                                                    needs_threshold = False))\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "full_gbm_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "\n",
    "#Printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))\n",
    "\n",
    "#Tuned Parameters  : {'learning_rate': 0.7000000000000001, 'max_depth': 2, 'n_estimators': 200}\n",
    "#Tuned Training AUC: 0.6486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING the model object with hyperparameters\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate = 0.7,\n",
    "                                       max_depth     = 2,\n",
    "                                       n_estimators  = 200,\n",
    "                                       random_state  = 222)\n",
    "\n",
    "\n",
    "#FIT step is needed as we are not using .best_estimator\n",
    "gbm_tuned_fit = gbm_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "#SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(X_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(X_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#Appending to model_performance\n",
    "model_performance.append(['Tuned GBM',\n",
    "                           gbm_train_acc,\n",
    "                           gbm_test_acc,\n",
    "                           gbm_auc])\n",
    "\n",
    "\n",
    "#Checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to DataFrame and checking the results\n",
    "model_performance_df = pd.DataFrame(model_performance[1:], columns = model_performance[0])\n",
    "model_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding each model's performance\n",
    "model_performance_df.sort_values(by = 'AUC Value',\n",
    "                                 ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the DataFrame to Excel\n",
    "model_performance_df.to_excel('Classification Model Performance.xlsx',\n",
    "                              index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>The final model selected is the Tuned Tree model that has an AUC of 0.8065 and a Testing score of 0.8337</h6>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
